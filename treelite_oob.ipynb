{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c1c62e-5b94-45c8-807a-44cfd8bfc6c1",
   "metadata": {},
   "source": [
    "# Hacking `treelite` for Out-Of-Bag Random Forest Predictions\n",
    "\n",
    "Random forests are great. So great that I implore you to read one of the thousand articles about random forests starting [here](https://en.wikipedia.org/wiki/Random_forest). Each tree in a random forest is constructed from independent samples of the source data (a la [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating)). This leads to two interesting features:\n",
    "\n",
    "* **Prediction performance**: Random forests generally do not overfit when one cranks up the number of trees while mostly enjoying variance reduction gains. Hence training a forest with a large number of trees is generally desirable albeit computationally expensive. Predicting through such a forest is also expensive. Fortunately, [treelite](https://treelite.readthedocs.io/en/latest/) takes care of prediction (and only prediction, not training) performance. Since any fancy (or plain), causal (or not), honest (or cheating) random forest are pretty much the same **at prediction time** -- bunch of split test nodes and leaf average values -- treelite can convert a bespoke representation of random forest into a fast C one. This works for xgboost, lightgbm, sklearn, or even your own hand rolled random forest model. The treelite representation of random forest can then be compiled into a quick C shared object or deployed to CUDA ([cuml](https://github.com/rapidsai/cuml)) / [Sagemaker Neo](https://github.com/neo-ai/neo-ai-dlr) for glory.\n",
    "* **Out-of-bag errors**: Instead of having to do an explicit train test split, one can enjoy the convenience of having random forests calculate out-of-bag errors by making each individual tree predict on the subset of the data that was not used to train the tree. This is great and useful in a lot of practical applications. **However, this is not supported by `treelite`** as it requires each forest prediction call to only query from a subset of trees in the forest. Instead, the `treelite` interface only supports querying for an average value across all trees in the forest.\n",
    "\n",
    "In this article, we'll see how we can (ab)use `treelite` to get out-of-bag predictions. Additionally, I hope that this will help make the `treelite` package more popular among causal circles.\n",
    "\n",
    "## Getting OOB Predictions and Sampling Indices from `sklearn`\n",
    "\n",
    "We first start with a simple `sklearn.ensemble.RandomForestRegressor` model trained on the `california_housing` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e26b34-6e40-4ab1-8f9b-0b4c6cf483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy\n",
    "import treelite\n",
    "import treelite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556067a8-4e9f-42f2-928e-1f9edd5f3051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'treelite-oob'\n",
      "/home/jovyan/treelite-oob\n"
     ]
    }
   ],
   "source": [
    "%cd treelite-oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310bd377-9e28-4c61-a0da-6507aa70ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sklearn.datasets.fetch_california_housing(data_home = './bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86a0fe6-af52-4b36-ae93-0121f168e62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = d['data']\n",
    "y = d['target']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cbb840-2949-41f4-bb88-817192a6fbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=3, oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=3, oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=3, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = sklearn.ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 3, oob_score = True, random_state = 0)\n",
    "forest.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29253bef-76ab-482b-9b7f-e486bf74b900",
   "metadata": {},
   "source": [
    "We can now query the model for its training score, oob score, and oob predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675f1fcb-faee-4173-809e-b8234a33261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5613827712406585 0.5539804583170151 100\n",
      "[4.26892639 4.48427396 3.62823672 ... 1.20096897 1.40188469 1.21079713]\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(x, y), forest.oob_score_, len(forest.estimators_))\n",
    "print(forest.oob_prediction_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1492b26-87ee-4232-915e-4c4810726496",
   "metadata": {},
   "source": [
    "Indeed, we can peel under the hood a little and see exactly how `oob_prediction_` is calculated. When one looks at the python source code for that, one can see that it's essentially calculating the following for a given tree `i`\n",
    "\n",
    "* Get the observations that the tree `i` did not bootstrap sample (i.e. `unsampled_indices`)\n",
    "* Have that tree `i` predict `x[unsampled_indices, :]` i.e. the part of the data that tree `i` did not see\n",
    "\n",
    "Then, over all trees, average those predictions by the number of trees that contributed to any particular prediction.\n",
    "\n",
    "I replicated the `oob_prediction_` code below for both clarity and since it'll be useful in the `treelite` reproduction of oob later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b800d447-90a3-477a-8f52-b0fd23fc93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that my reproduction of bootstrap sampling indices is accurate\n",
    "\n",
    "oob_preds = numpy.zeros(y.shape[0])\n",
    "n_oob_preds = numpy.zeros(y.shape[0])\n",
    "\n",
    "for i in range(forest.n_estimators):\n",
    "    tree = forest.estimators_[i]\n",
    "    unsampled_indices = sklearn.ensemble._forest._generate_unsampled_indices(tree.random_state, y.shape[0], y.shape[0])\n",
    "    oob_pred = tree.predict(x[unsampled_indices, :])\n",
    "    oob_preds[unsampled_indices] += oob_pred\n",
    "    n_oob_preds[unsampled_indices] += 1\n",
    "\n",
    "n_oob_preds[n_oob_preds == 0] = 1\n",
    "oob_preds /= n_oob_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4e7a7b-caf7-4b9f-9664-191bf08f21db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.all(oob_preds == forest.oob_prediction_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d720f-16f8-43e2-8ea5-6a9c552e40f3",
   "metadata": {},
   "source": [
    "## Converting `sklearn` Model to `treelite` (Vanilla)\n",
    "\n",
    "Now we can convert this `sklearn.ensemble.RandomForestRegressor` to a `treelite` model. `treelite` comes with a converter for `sklearn` models so we use that directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d35a64-b7aa-4af0-9675-898ca683f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:29] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 32 translation units.\n"
     ]
    }
   ],
   "source": [
    "model_sklearn = treelite.sklearn.import_model(forest)\n",
    "model_sklearn.export_lib(toolchain = 'gcc', libpath = './bin/model_sklearn.so', params = {'parallel_comp': 32})\n",
    "predictor_sklearn = treelite_runtime.Predictor('./bin/model_sklearn.so')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892cd163-653d-40ba-9d8c-47cfdf2a7bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:31] ../src/predictor/predictor.cc:464: Treelite: Finished prediction in 0.00171971 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_truth = forest.predict(x)\n",
    "pred_sklearn = predictor_sklearn.predict(treelite_runtime.DMatrix(x, dtype = 'float32'), verbose = True)\n",
    "\n",
    "numpy.allclose(pred_truth, pred_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11342fb-25aa-48c4-9046-84432daf2adb",
   "metadata": {},
   "source": [
    "We find that all the predictions closely match up. Excellent.\n",
    "\n",
    "**However, we have lost the ability to make OOB predictions**. Oh no woe be us. Fortunately, `treelite` provides us the knobs to restore this ability.\n",
    "\n",
    "First, let's leave the precanned `treelite.sklearn.import_model` adapter behind and instead construct the `treelite` model from the `sklearn` model by hand. We do so by literally following the `treelite` tutorial in the docs.\n",
    "\n",
    "## Converting `sklearn` Model to `treelite` (By Hand)\n",
    "\n",
    "In order to do this, we basically loop through each tree in the forest and traverse the `sklearn` tree structure iteratively. Most of the hard part is figuring out the `sklearn` API for each individual tree. The guys over at `treelite` did an excellent job with the tutorial and I just copied their code over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e923624c-8b60-47de-bc76-7364dc3bc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_node(treelite_tree, sklearn_tree, node_id, sklearn_model):\n",
    "    if sklearn_tree.children_left[node_id] == -1:  # leaf node\n",
    "        process_leaf_node(treelite_tree, sklearn_tree, node_id, sklearn_model)\n",
    "    else:  # test node\n",
    "        process_test_node(treelite_tree, sklearn_tree, node_id, sklearn_model)\n",
    "\n",
    "def process_test_node(treelite_tree, sklearn_tree, node_id, sklearn_model):\n",
    "    # Process a test node with a given node ID. We shall assume that all tree ensembles in\n",
    "    # scikit-learn use only numerical splits.\n",
    "    treelite_tree[node_id].set_numerical_test_node(\n",
    "        feature_id = sklearn_tree.feature[node_id],\n",
    "        opname = '<=',\n",
    "        threshold = sklearn_tree.threshold[node_id],\n",
    "        threshold_type = 'float64',\n",
    "        default_left = True,\n",
    "        left_child_key = sklearn_tree.children_left[node_id],\n",
    "        right_child_key = sklearn_tree.children_right[node_id]\n",
    "    )\n",
    "\n",
    "def process_leaf_node(treelite_tree, sklearn_tree, node_id, sklearn_model):\n",
    "    # Process a test node with a given node ID\n",
    "    # The `value` attribute stores the output for every leaf node.\n",
    "    leaf_value = sklearn_tree.value[node_id].squeeze()\n",
    "    # Initialize the leaf node with given node ID\n",
    "    treelite_tree[node_id].set_leaf_node(leaf_value, leaf_value_type = 'float64')\n",
    "\n",
    "\n",
    "builder_hand = treelite.ModelBuilder(num_feature = forest.n_features_in_, average_tree_output = True, threshold_type = 'float64', leaf_output_type = 'float64')\n",
    "for i in range(forest.n_estimators):\n",
    "    sklearn_tree = forest.estimators_[i].tree_\n",
    "    treelite_tree = treelite.ModelBuilder.Tree(threshold_type = 'float64', leaf_output_type = 'float64')\n",
    "    \n",
    "    for node_id in range(sklearn_tree.node_count):\n",
    "        process_node(treelite_tree, sklearn_tree, node_id, sklearn_model = forest)\n",
    "    treelite_tree[0].set_root()\n",
    "    builder_hand.append(treelite_tree)\n",
    "\n",
    "model_hand = builder_hand.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61cf7aa-71a0-4a06-b3c6-b5544a77cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:31] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 32 translation units.\n"
     ]
    }
   ],
   "source": [
    "model_hand.export_lib(toolchain = 'gcc', libpath = './bin/model_hand.so', params = {'parallel_comp': 32})\n",
    "predictor_hand = treelite_runtime.Predictor('./bin/model_hand.so')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41092be3-e70c-40f4-b214-ef534863dbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[03:05:34] ../src/predictor/predictor.cc:464: Treelite: Finished prediction in 0.00194001 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictor_hand.leaf_output_type)\n",
    "\n",
    "pred_truth = forest.predict(x)\n",
    "pred_hand = predictor_hand.predict(treelite_runtime.DMatrix(x, dtype = 'float32'), verbose = True)\n",
    "\n",
    "numpy.allclose(pred_truth, pred_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432458b2-c3c4-485c-9241-cfc2f1c428e3",
   "metadata": {},
   "source": [
    "The hand constructed `treelite` model matches the original `sklearn` random forest predictions as well. That's great.\n",
    "\n",
    "Now let's add in the fun out-of-bag predictions.\n",
    "\n",
    "## Adding Out-Of-Bag Predictions to `treelite`\n",
    "\n",
    "Let's look at our random forest again. We have `ntree = 100` trees in the random forest. When we predict through `m` rows, we get a `m` length output: each element is a prediction for the `i`-th row of data. That's simple enough.\n",
    "\n",
    "Suppose we were instead able to get back a `m * ntree` matrix where\n",
    "\n",
    "* Each row `i` in `m` corresponds to the predictions for a single row in the prediction data (same as before)\n",
    "* Each column `j` in `ntree` corresponds to tree `j`'s prediction for that row.\n",
    "\n",
    "In other words, `prediction[i, j]` would mean that for the `i`-th observation, tree `j` predicted `prediction[i, j]`. In order to get the average prediction (which is what we would do when predicting), we can take `avg(prediction[i, :])`. \n",
    "\n",
    "If we wanted to predict out-of-bag, then we would simply subset `prediction[i, :]` to the specific trees that did not see observation `i` in the original training data.\n",
    "\n",
    "* For example, our current data has `x.shape = (20640, 8)`.\n",
    "* Suppose tree `5` was trained on all even observations (i.e. observations `[0, 2, 4, 6, 8, ...]`\n",
    "* Then, the tree `5`'s predictions can only be used to predict observations `[1, 3, 5, 7, 9, ...]`\n",
    "* So the out-of-bag prediction for row `1` should contain tree `5`'s prediction for row `1`.\n",
    "\n",
    "Then, **we just have to get `treelite` to return an array instead of a single average value at its leaf nodes!** Turns out that's possible because `treelite` supports [multi-class classification](https://treelite.readthedocs.io/en/latest/tutorials/builder.html#multi-class-classification-with-randomforestclassifier) and we can (ab)use that interface to return an array at leaf nodes.\n",
    "\n",
    "We do this below. Key tips:\n",
    "\n",
    "* Make sure that the `treelite` tree is constructed using `pred_transform = 'identity_multiclass'` so that the prediction values are preserved (vs. be converted into a classification prediction\n",
    "* The leaf vector is `zeros` except for the element at the `tree_index`. i.e. tree `1`'s vector is `[pred_1, 0, 0, 0, 0, ...]`, tree `2`'s vector is `[pred_2, 0, 0, 0, 0, ...]`. Then, when `treelite` finally averages the vectors column wise for a prediction, the resulting vector will be `[pred_1 / ntree, pred_2 / ntree, pred_3 / ntree, ...]`. Do remember to multiply the values back by `ntree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7290c4ed-da17-4698-a690-79a63b3bfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model, tree_index):\n",
    "    if sklearn_tree.children_left[node_id] == -1:  # leaf node\n",
    "        process_leaf_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model, tree_index)\n",
    "    else:  # test node\n",
    "        process_test_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model)\n",
    "\n",
    "def process_test_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model):\n",
    "    # Process a test node with a given node ID. We shall assume that all tree ensembles in\n",
    "    # scikit-learn use only numerical splits.\n",
    "    treelite_tree[node_id].set_numerical_test_node(\n",
    "        feature_id = sklearn_tree.feature[node_id],\n",
    "        opname = '<=',\n",
    "        threshold = sklearn_tree.threshold[node_id],\n",
    "        threshold_type = 'float64',\n",
    "        default_left = True,\n",
    "        left_child_key = sklearn_tree.children_left[node_id],\n",
    "        right_child_key = sklearn_tree.children_right[node_id]\n",
    "    )\n",
    "\n",
    "def process_leaf_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model, tree_index):\n",
    "    # Process a test node with a given node ID\n",
    "    # The `value` attribute stores the output for every leaf node.\n",
    "    leaf_value = sklearn_tree.value[node_id].squeeze()\n",
    "    # Initialize the leaf node with given node ID\n",
    "    # use a vector by tree index\n",
    "    leaf_vector = numpy.zeros(sklearn_model.n_estimators)\n",
    "    leaf_vector[tree_index] = leaf_value\n",
    "    treelite_tree[node_id].set_leaf_node(leaf_vector, leaf_value_type = 'float64')\n",
    "\n",
    "\n",
    "builder_oob = treelite.ModelBuilder(num_feature = forest.n_features_in_, average_tree_output = True, \n",
    "                                    pred_transform = 'identity_multiclass', num_class = forest.n_estimators,\n",
    "                                    threshold_type = 'float64', leaf_output_type = 'float64')\n",
    "for i in range(forest.n_estimators):\n",
    "    sklearn_tree = forest.estimators_[i].tree_\n",
    "    treelite_tree = treelite.ModelBuilder.Tree(threshold_type = 'float64', leaf_output_type = 'float64')\n",
    "    \n",
    "    for node_id in range(sklearn_tree.node_count):\n",
    "        process_node_oob(treelite_tree, sklearn_tree, node_id, sklearn_model = forest, tree_index = i)\n",
    "    treelite_tree[0].set_root()\n",
    "    builder_oob.append(treelite_tree)\n",
    "\n",
    "model_oob = builder_oob.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac958d9-aa6b-4a40-a6dc-7b7c5b023659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:35] ../src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 32 translation units.\n"
     ]
    }
   ],
   "source": [
    "model_oob.export_lib(toolchain = 'gcc', libpath = './bin/model_oob.so', params = {'parallel_comp': 32})\n",
    "predictor_oob = treelite_runtime.Predictor('./bin/model_oob.so')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b31452-7efe-47b5-9d14-fd2ba803f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[03:05:45] ../src/predictor/predictor.cc:464: Treelite: Finished prediction in 0.0262787 sec\n"
     ]
    }
   ],
   "source": [
    "print(predictor_oob.leaf_output_type)\n",
    "\n",
    "pred_truth = forest.predict(x)\n",
    "pred_oob = predictor_oob.predict(treelite_runtime.DMatrix(x, dtype = 'float32'), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f651f709-e03d-48a1-8762-d7643871832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04560552, 0.04570032, 0.04586979, ..., 0.0412651 , 0.04568925,\n",
       "        0.04634979],\n",
       "       [0.04560552, 0.04570032, 0.04586979, ..., 0.0412651 , 0.04568925,\n",
       "        0.04634979],\n",
       "       [0.0370852 , 0.03759835, 0.03906212, ..., 0.02751148, 0.03786934,\n",
       "        0.03836738],\n",
       "       ...,\n",
       "       [0.01124395, 0.01140075, 0.01148075, ..., 0.01163021, 0.01270512,\n",
       "        0.0117942 ],\n",
       "       [0.01124395, 0.01140075, 0.01148075, ..., 0.01163021, 0.01895014,\n",
       "        0.0117942 ],\n",
       "       [0.01124395, 0.01140075, 0.01148075, ..., 0.01163021, 0.01270512,\n",
       "        0.0117942 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_oob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a119766-f34b-4814-88ba-73c82cd4d914",
   "metadata": {},
   "source": [
    "Let's take a look at the `pred_oob` output to see what we're dealing with.\n",
    "\n",
    "* The first row (`pred_oob[0, :]`) corresponds to the first row of the training data (`x[0, :]`)\n",
    "* The first element of the first row (`pred_oob[0, 0]`) is the prediction made by tree `0` for `x[0, :]`. That means the first tree predicted `0.04560552` for `x[0, :]`, the second tree predicted `0.04570032` for `x[0, :]` etc.\n",
    "* The out-of-bag prediction for `x[0, :]` is then the subset of `pred_oob[0, :]` produced by trees that have not seen `x[0, :]`.\n",
    "\n",
    "Hmm, where have we seen that `unsampled_indices` by tree before? Oh right! In the `sklearn` OOB reproduction at the top! We reproduce this below with a slightly different objective: to produce a boolean matrix `ntree * m` where `m = x.shape[0]` (rows of observations) where an element is true of a tree has seen an observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97f1810d-1104-4cad-aabb-baeaca545cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True, False,  True],\n",
       "       [ True, False,  True, ..., False,  True, False],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [ True, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_by_tree = numpy.ones((forest.n_estimators, y.shape[0]), dtype = 'bool')\n",
    "for i in range(forest.n_estimators):\n",
    "    tree = forest.estimators_[i]\n",
    "    unsampled_indices = sklearn.ensemble._forest._generate_unsampled_indices(tree.random_state, y.shape[0], y.shape[0])\n",
    "    sampled_by_tree[i, unsampled_indices] = 0\n",
    "\n",
    "print(sampled_by_tree.shape)\n",
    "sampled_by_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520fc261-861a-4ecb-8278-0251bbec21ed",
   "metadata": {},
   "source": [
    "Let's take a look at the first column of `sampled_by_tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a5c6e7-feb6-4192-a31c-1ac5e26c091f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False,  True, False, False,\n",
       "       False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first observation were sampled by these trees\n",
    "sampled_by_tree[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28431612-a1c0-4235-b0f2-9e31b810ee19",
   "metadata": {},
   "source": [
    "This means that the first observation was\n",
    "\n",
    "* NOT sampled by tree `0, 4, 5, ...` during training\n",
    "* Sampled by tree `1, 2, 3, ...` during training\n",
    "\n",
    "We can use this information to subset `pred_oob` to the predictions made by trees that did not sample `x[0, :]`.\n",
    "\n",
    "First, we get the prediction made by all trees for `x[0, :]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709dcf35-8790-46ab-8657-91755a87ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04560552, 0.04570032, 0.04586979, 0.04569512, 0.03821047,\n",
       "       0.04371979, 0.04589362, 0.0402859 , 0.04581989, 0.04577618,\n",
       "       0.0400397 , 0.04544045, 0.03926476, 0.04001247, 0.04592836,\n",
       "       0.04122305, 0.0412437 , 0.03999852, 0.04589456, 0.0392282 ,\n",
       "       0.04590753, 0.04582622, 0.03946538, 0.0397702 , 0.04303944,\n",
       "       0.04600728, 0.04095347, 0.04560237, 0.04599909, 0.04586869,\n",
       "       0.03972882, 0.03990556, 0.04738166, 0.04646981, 0.03913978,\n",
       "       0.04602887, 0.04108574, 0.04012991, 0.04545299, 0.03930916,\n",
       "       0.04622483, 0.04627873, 0.04550603, 0.04582898, 0.0462196 ,\n",
       "       0.04567977, 0.04682332, 0.04071481, 0.04121475, 0.04610376,\n",
       "       0.04565651, 0.04593056, 0.0458457 , 0.04548754, 0.04324523,\n",
       "       0.04683947, 0.03986283, 0.04567417, 0.04694492, 0.04606315,\n",
       "       0.04620698, 0.03963573, 0.0394904 , 0.0390622 , 0.03992085,\n",
       "       0.04229458, 0.04585559, 0.04605572, 0.04589857, 0.03961649,\n",
       "       0.04561612, 0.04726357, 0.04569323, 0.04021279, 0.04561119,\n",
       "       0.04501901, 0.04585619, 0.04556664, 0.04586562, 0.04679627,\n",
       "       0.0397793 , 0.04570687, 0.03981519, 0.04555079, 0.04583251,\n",
       "       0.04702762, 0.04587204, 0.04042515, 0.03957632, 0.04683772,\n",
       "       0.04580305, 0.04289789, 0.0419671 , 0.03997833, 0.04718018,\n",
       "       0.04519706, 0.0459235 , 0.0412651 , 0.04568925, 0.04634979])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for first observation by these trees\n",
    "pred_oob.T[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b3963-7c6a-4d1f-99a6-2269b281e829",
   "metadata": {},
   "source": [
    "Subsetting them to `sampled_by_tree[:, 0]` gives us the following smaller set of predictions. These are the out-of-bag predictions for `x[0, :]`, albeit scaled down because we divided through `ntree.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0e8522-5c8a-4e5d-9753-0f349877ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04560552, 0.03821047, 0.04371979, 0.04581989, 0.04577618,\n",
       "       0.04592836, 0.03999852, 0.0392282 , 0.04590753, 0.04303944,\n",
       "       0.03972882, 0.03990556, 0.04108574, 0.04012991, 0.03930916,\n",
       "       0.04567977, 0.04071481, 0.04121475, 0.04593056, 0.04324523,\n",
       "       0.04567417, 0.04606315, 0.03963573, 0.0394904 , 0.0390622 ,\n",
       "       0.04605572, 0.04589857, 0.04586562, 0.0397793 , 0.04042515,\n",
       "       0.03957632, 0.04683772, 0.0419671 , 0.0412651 , 0.04634979])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_oob.T[:, 0][numpy.invert(sampled_by_tree[:, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f7d16-aafb-4d19-8c65-e81d107722b2",
   "metadata": {},
   "source": [
    "Taking the average of these and scaling them back up gives us the out-of-bag prediction for `x[0, :]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4be582a-7eb7-444e-8731-7ef8a5e72fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.268926388720941"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(pred_oob.T[:, 0][numpy.invert(sampled_by_tree[:, 0])]) * forest.n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5574b9a-377d-4bda-be1f-6c5dbc770400",
   "metadata": {},
   "source": [
    "We can do this for all of `x` and we check that it's indeed equal to `sklearn`'s `oob_prediction_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0522b39d-c604-4fe8-a499-dbdecf81cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_oob_mean = numpy.array([numpy.mean(pred_oob.T[:, i][numpy.invert(sampled_by_tree[:, i])]) * forest.n_estimators for i in range(y.shape[0])])\n",
    "numpy.allclose(forest.oob_prediction_, pred_oob_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c762a6-cc86-4eca-9a83-78b64d03452a",
   "metadata": {},
   "source": [
    "We now have blazingly fast out of bag predictions for random forests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
